# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L4Y4zpP1xp6JA1uqZFCD1YZWB5k51Myv
"""

# Seasonnality
def seasonal_decomposition(timeseries, period, model='additive'):
    return seasonal_decompose(timeseries, model=model, period=period)

def plot_decomposition(axs, timeseries, decomposition, title):
    axs[0].plot(timeseries, label='Original')
    axs[0].set_title(f'Original Time Series\n{title}')
    axs[0].grid(True)

    axs[1].plot(decomposition.trend.dropna(), label='Trend')
    axs[1].set_title(f'Trend Component\n{title}')
    axs[1].grid(True)

    axs[2].plot(decomposition.seasonal.dropna(), label='Seasonal')
    axs[2].set_title(f'Seasonal Component\n{title}')
    axs[2].grid(True)

    axs[3].plot(decomposition.resid.dropna(), label='Residual')
    axs[3].set_title(f'Residual Component\n{title}')
    axs[3].grid(True)

def analyze_seasonality(dataframes1, dataframes2, dataframes3, period_dict):
    datasets = {'dataframes': dataframes1, 'dataframes_79': dataframes2, 'dataframes_10': dataframes3}

    sheets = list(dataframes1.keys())  # Assuming all dataframes have the same sheets

    for sheet in sheets:
        nrows = 4  # Original, Trend, Seasonal, Residual
        ncols = len(datasets)  # Three datasets
        fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 15))
        fig.suptitle(f'Seasonal Decomposition for {sheet}', fontsize=16)

        for j, (dataset_name, dataset) in enumerate(datasets.items()):
            df = dataset.get(sheet)
            if df is None or 'USD' not in df.columns:
                continue

            time_series = df['USD'].dropna()
            period = period_dict.get(sheet, 12)

            decomposition = seasonal_decomposition(time_series, period)

            plot_decomposition(axs[:, j], time_series, decomposition, title=f'{dataset_name}')

        plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to include the suptitle

        # Save the figure as a JPEG image
        plt.savefig(f'{sheet}.jpeg', format='jpeg')

        plt.show()

def optimize_arima(timeseries, p_values, d_values, q_values):
    best_aic = np.inf
    best_order = None
    best_model = None

    for p in p_values:
        for d in d_values:
            for q in q_values:
                try:
                    model = sm.tsa.ARIMA(timeseries, order=(p, d, q))
                    results = model.fit()
                    if results.aic < best_aic:
                        best_aic = results.aic
                        best_order = (p, d, q)
                        best_model = results
                except:
                    continue

    return best_order, best_aic, best_model

def optimize_sarima(timeseries, p_values, d_values, q_values, P_values, D_values, Q_values, m):
    best_aic = np.inf
    best_order = None
    best_seasonal_order = None
    best_model = None

    for p in p_values:
        for d in d_values:
            for q in q_values:
                for P in P_values:
                    for D in D_values:
                        for Q in Q_values:
                            try:
                                seasonal_order = (P, D, Q, m)
                                model = SARIMAX(timeseries, order=(p, d, q), seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)
                                results = model.fit()
                                if results.aic < best_aic:
                                    best_aic = results.aic
                                    best_order = (p, d, q)
                                    best_seasonal_order = seasonal_order
                                    best_model = results
                            except:
                                continue

    return best_order, best_seasonal_order, best_aic, best_model

def arima_sarima_analysis(data_dict, sheet_names):
    # Define the p, d, q parameters to take any value between 0 and 2
    p_values = range(0, 2)
    d_values = range(0, 1)
    q_values = range(0, 2)

    # Define the seasonal p, d, q parameters and m for SARIMA
    P_values = range(0, 2)
    D_values = range(0, 1)
    Q_values = range(0, 2)
    m_values = {'Yearly_EoP': 1, 'Quarterly_EoP': 4, 'Monthly_EoP': 12, 'Weekly_EoP': 52, 'Daily': 365}

    results = []

    # Iterate over each dataframe and each sheet
    for df_name, dataframes in data_dict.items():
        for sheet in sheet_names:
            if sheet not in dataframes:
                continue
            df = dataframes[sheet]

            if 'USD' not in df.columns:
                print(f"'USD' column not found in {sheet} of {df_name}. Skipping.")
                continue

            time_series = df['USD'].dropna()  # Drop missing values if any

            # Determine seasonal period for SARIMA
            m = m_values.get(sheet, 1)

            # ARIMA optimization
            arima_order, arima_aic, _ = optimize_arima(time_series, p_values, d_values, q_values)

            # SARIMA optimization
            sarima_order, sarima_seasonal_order, sarima_aic, _ = optimize_sarima(time_series, p_values, d_values, q_values, P_values, D_values, Q_values, m)

            # Store results
            results.append({
                'Dataframe': df_name,
                'Sheet': sheet,
                'ARIMA Order': arima_order,
                'ARIMA AIC': arima_aic,
                'SARIMA Order': sarima_order,
                'SARIMA Seasonal Order': sarima_seasonal_order,
                'SARIMA AIC': sarima_aic
            })

    # Convert results to a DataFrame for display
    results_df = pd.DataFrame(results)
    results_df.set_index(['Dataframe', 'Sheet'], inplace=True)
    results_df.columns = ['ARIMA Order', 'ARIMA AIC', 'SARIMA Order', 'SARIMA Seasonal Order', 'SARIMA AIC']

    return results_df

# Select optimal ARCH/GARCH processus
def optimize_arch_garch(timeseries, p_values, q_values):
    """
    Optimize ARCH/GARCH model based on AIC.

    Args:
    - timeseries (pd.Series): The time series data.
    - p_values (range): Range of p values for GARCH.
    - q_values (range): Range of q values for GARCH and ARCH.

    Returns:
    - tuple: Best model order, best AIC, and the best model.
    """
    best_aic = np.inf
    best_order = None
    best_model = None
    model_type = None

    # Iterate over ARCH models
    for q in q_values:
        try:
            model = arch_model(timeseries, vol='Arch', p=q)
            results = model.fit(disp="off")
            if results.aic < best_aic:
                best_aic = results.aic
                best_order = (0, q)  # ARCH model
                best_model = results
                model_type = 'ARCH'
        except:
            continue

    # Iterate over GARCH models
    for p, q in itertools.product(p_values, q_values):
        try:
            model = arch_model(timeseries, vol='Garch', p=p, q=q)
            results = model.fit(disp="off")
            if results.aic < best_aic:
                best_aic = results.aic
                best_order = (p, q)  # GARCH model
                best_model = results
                model_type = 'GARCH'
        except:
            continue

    return best_order, best_aic, best_model, model_type

def arch_garch_analysis(data_dict: Dict[str, Dict[str, pd.DataFrame]], sheets_to_read: List[str]):
    """
    Analyze ARCH and GARCH models for given sheets and data dictionaries.

    Args:
    - data_dict (Dict[str, Dict[str, pd.DataFrame]]): Dictionary with data source names as keys and data dictionaries as values.
    - sheets_to_read (List[str]): List of sheet names to analyze.

    Returns:
    - pd.DataFrame: DataFrame with ARCH and GARCH optimization results.
    """
    # Define the p, q parameters to take any value between 0 and 2
    p_values = range(0, 3)
    q_values = range(0, 3)

    results = []

    # Iterate over each dataframe and each sheet
    for df_name, dataframes in data_dict.items():
        for sheet in sheets_to_read:
            if sheet not in dataframes:
                continue
            df = dataframes[sheet]

            if 'USD' not in df.columns:
                print(f"'USD' column not found in {sheet} of {df_name}. Skipping.")
                continue

            time_series = df['USD'].dropna()  # Drop missing values if any

            # ARCH/GARCH optimization
            order, aic, model, model_type = optimize_arch_garch(time_series, p_values, q_values)

            # Store results
            results.append({
                'Dataframe': df_name,
                'Sheet': sheet,
                'Model Type': model_type,
                'Order': order,
                'AIC': aic
            })

    # Convert results to a DataFrame for display
    results_df = pd.DataFrame(results)
    results_df.set_index(['Dataframe', 'Sheet'], inplace=True)
    results_df.columns = ['Model Type', 'Order', 'AIC']

    return results_df

# Call this function after pick the right(p,d,q) for SARIMA based on AIC
def sarima_article(y,order,seasonal_order,seasonal_period,pred_date,y_to_train, y_to_test, output_filename):
    """
    Fit SARIMA models with different forecast steps and save forecasts to an Excel file.
    should be use !pip install pandas==1.5.2
    Parameters:
    - y (array-like): Time series data to be modeled.
    - order (tuple): SARIMA order parameters (p, d, q).
    - seasonal_order (tuple): Seasonal SARIMA order parameters (P, D, Q, s).
    - seasonal_period (int): Seasonal period of the time series.
    - pred_date (int): The start date for forecasting.
    - y_to_train (array-like): Training data for SARIMA models.
    - y_to_test (array-like): Test data for evaluating the model.

    Returns:
    - None

    This function fits SARIMA models with different forecast steps to the provided time series data.
    It saves the forecasts to an Excel file named 'output_arima.xlsx'.
    """
    # fit the model
    mod = sm.tsa.statespace.SARIMAX(y,
                                order=order,
                                seasonal_order=seasonal_order,
                                enforce_stationarity=False,
                                enforce_invertibility=False)
    results = mod.fit()
    pred = results.get_prediction(start=pred_date, dynamic=False)
    y_forecasted = results.predict()[(len(y_to_train)):]
    y_forecasted.index = range(0, (len(y_to_test)))

    forecast_steps = 1
    pred1 = []
    for i in range((int(len(y_to_test)/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred1.extend(sarima_forecast)

    forecast_steps = 2
    pred2 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred2.extend(sarima_forecast)

    forecast_steps = 3
    pred3 = []
    for i in range((int(len(y_to_test)/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred3.extend(sarima_forecast)

    forecast_steps = 4
    pred4 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred4.extend(sarima_forecast)

    forecast_steps = 5
    pred5 = []
    for i in range((int(len(y_to_test)/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred5.extend(sarima_forecast)

    forecast_steps = 6
    pred6 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred6.extend(sarima_forecast)

    forecast_steps = 7
    pred7 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred7.extend(sarima_forecast)

    forecast_steps = 8
    pred8 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred8.extend(sarima_forecast)

    forecast_steps = 9
    pred9 = []
    for i in range((int(len(y_to_test)/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred9.extend(sarima_forecast)

    forecast_steps = 10
    pred10 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred10.extend(sarima_forecast)

    forecast_steps = 11
    pred11 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred11.extend(sarima_forecast)

    forecast_steps = 12
    pred12 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred12.extend(sarima_forecast)

    forecast_steps = 18
    pred18 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred18.extend(sarima_forecast)

    forecast_steps = 24
    pred24 = []
    for i in range((int((len(y_to_test))/forecast_steps))):
        sarima_fit = sm.tsa.SARIMAX(y_to_train.append(y_to_test[:i+forecast_steps]), order=order, seasonal_order=seasonal_order).fit()
        sarima_forecast = sarima_fit.forecast(steps=forecast_steps)
        pred24.extend(sarima_forecast)


    pred_dynamic = results.predict(start = (len(y_to_train)+1), end =len(y), dynamic =True)
    pred_dynamic.index = range(0, len(y_to_test))

    # Create a DataFrame
    # Reference length
    ref_len = len(y_to_test)

    # Dictionary of your series/dataframes/lists with their correct names (excluding y_forecasted)
    y_lists = {'pred1': pred1, 'pred2': pred2, 'pred3': pred3, 'pred4': pred4,
        'pred5': pred5, 'pred6': pred6, 'pred7': pred7, 'pred8': pred8, 'pred9': pred9,
        'pred10': pred10, 'pred11': pred11, 'pred12': pred12, 'pred18': pred18,
        'pred24': pred24, 'pred_dynamic': pred_dynamic}

    # Dictionary to hold the adjusted series/dataframes
    data = {}

    # Process each series/dataframe/list
    for name, y_list in y_lists.items():
        # Convert list to Series if necessary
        if isinstance(y_list, list):
            y_list = pd.Series(y_list)

        # Adjust the length
        if len(y_list) < ref_len:
            # Pad with NaN to match the length of y_forecasted
            y_list = y_list.reindex(range(ref_len)).reset_index(drop=True)
        elif len(y_list) > ref_len:
            # Truncate to match the length of y_forecasted
            y_list = y_list.iloc[:ref_len].reset_index(drop=True)
        # No action if len(y_list) == ref_len

        # Add to the dictionary with the original name
        data[name] = y_list

    # Create dataframe

    y_acual = y[(len(y_to_train)):]
    y_acual.index = range(0, (len(y_to_test)))

    data['actual'] = y_acual
    data['pred'] = y_forecasted
    df = pd.DataFrame(data)

    writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')
    # Convert the DataFrame to an Excel object
    df.to_excel(writer, sheet_name='Sheet1')
    # Save the Excel file
    writer.save()

def run_sarima(data_dicts, sarima_params, sheets_to_read, train_ratio=0.7):
    for data_key, dataframes in data_dicts.items():
        for sheet in sheets_to_read:
            y = dataframes[sheet]['USD']

            # Split the data
            split_index = int(len(y) * train_ratio)
            y_to_train = y[:split_index]
            y_to_test = y[split_index:]
            pred_date = split_index

            # Get SARIMA parameters for the current dataframe and sheet
            order = sarima_params[data_key][sheet]['order']
            seasonal_order = sarima_params[data_key][sheet]['seasonal_order']
            seasonal_period = seasonal_order[3]

            # Define the output filename
            output_filename = f"output_sarima_{data_key}_{sheet}.xlsx"

            # Run SARIMA model and save the results to an Excel file
            sarima_article(y, order, seasonal_order, seasonal_period, pred_date, y_to_train, y_to_test, output_filename)

            print(f"Completed SARIMA for {data_key} - {sheet}")



def run_arima(data_dicts, sarima_params, sheets_to_read, train_ratio=0.7):
    for data_key, dataframes in data_dicts.items():
        for sheet in sheets_to_read:
            y = dataframes[sheet]['USD']

            # Split the data
            split_index = int(len(y) * train_ratio)
            y_to_train = y[:split_index]
            y_to_test = y[split_index:]
            pred_date = split_index

            # Get SARIMA parameters for the current dataframe and sheet
            order = sarima_params[data_key][sheet]['order']
            seasonal_order = sarima_params[data_key][sheet]['seasonal_order']
            seasonal_period = seasonal_order[3]

            # Define the output filename
            output_filename = f"output_arima_{data_key}_{sheet}.xlsx"

            # Run SARIMA model and save the results to an Excel file
            sarima_article(y, order, seasonal_order, seasonal_period, pred_date, y_to_train, y_to_test, output_filename)

            print(f"Completed SARIMA for {data_key} - {sheet}")

#
def arch_article(y, p, q, y_to_train, y_to_test, split_index, output_filename):
    """
    Fit arch models with different forecast steps and save forecasts to an Excel file.
    should be use !pip install pandas==1.5.2

    Parameters:
    - y: The full time series data.
    - p: The order of the lag of the ARCH process.
    - q: The order of the lag of the GARCH process.
    - y_to_train: The training portion of the time series.
    - y_to_test: The testing portion of the time series.
    - split_index: Index to split the time series for training and testing.
    - output_filename: The name of the output Excel file.

    Returns:
    - None
    """
    def fit_and_forecast(horizon, y_train, y_test):
        model = arch_model(y_train, mean='Zero', vol='Garch', p=p, q=q, rescale=True)
        res = model.fit(disp='off')
        forecast = res.forecast(horizon=horizon, reindex=True)
        forecast_vol = forecast.variance.iloc[-horizon:, 0]
        forecast_mean = np.zeros(horizon)  # Mean forecast is zero
        forecast_returns = (forecast_mean + forecast_vol ** 0.5)
        y_forecasted = y_test[:horizon] + forecast_returns
        return y_forecasted

    y_lists = {}
    for forecast_steps in list(range(1, 13)) + [18, 24]:  # Forecast from 1 to 11 steps
        y_forecasts = []
        for i in range(len(y_to_test) - forecast_steps + 1): #
            y_train = y_to_train.append(y_to_test[:i+forecast_steps])
            y_forecasted = fit_and_forecast(forecast_steps, y_train, y_to_test[i:i+forecast_steps]) # y_to_test[i:i+forecast_steps]
            y_forecasts.extend(y_forecasted)
        y_lists[f'pred{forecast_steps}'] = y_forecasts

    # Dictionary to hold the adjusted series/dataframes
    ref_len = len(y_to_test)
    data = {}

    # Process each series/dataframe/list
    for name, y_list in y_lists.items():
        # Convert list to Series if necessary
        if isinstance(y_list, list):
            y_list = pd.Series(y_list)

        # Adjust the length
        if len(y_list) < ref_len:
            # Pad with NaN to match the length of y_forecasted
            y_list = y_list.reindex(range(ref_len)).reset_index(drop=True)
        elif len(y_list) > ref_len:
            # Truncate to match the length of y_forecasted
            y_list = y_list.iloc[:ref_len].reset_index(drop=True)
        # No action if len(y_list) == ref_len

        # Add to the dictionary with the original name
        data[name] = y_list

    # Create dataframe
    y_acual = y[(len(y_to_train)):]
    y_acual.index = range(0, (len(y_to_test)))

    data['actual'] = y_acual
    data['pred'] = y_forecasted
    df = pd.DataFrame(data)

    writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')
    # Convert the DataFrame to an Excel object
    df.to_excel(writer, sheet_name='Sheet1')
    # Save the Excel file
    writer.save()

def run_arch(data_dicts, garch_params, sheets_to_read, train_ratio=0.7):
    for data_key, dataframes in data_dicts.items():
        for sheet in sheets_to_read:
            y = dataframes[sheet]['USD']

            # Split the data
            split_index = int(len(y) * train_ratio)
            y_to_train = y[:split_index]
            y_to_test = y[split_index:]
            pred_date = split_index

            # Get SARIMA parameters for the current dataframe and sheet
            p = garch_params[data_key][sheet]['p']
            q = garch_params[data_key][sheet]['q']

            # Define the output filename
            output_filename = f"output_arch_{data_key}_{sheet}.xlsx"

            # Run arch model and save the results to an Excel file
            arch_article(y,p,q,y_to_train, y_to_test, split_index, output_filename)

            print(f"Completed ARCH for {data_key} - {sheet}")

