# -*- coding: utf-8 -*-
"""Wavelet-CNN-LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cUqKpPvegQsH1OYqcN-SA1LuT1Hg_2l5
"""

import numpy as np
import pandas as pd
import pywt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense
import matplotlib.pyplot as plt

def wavelet_decomposition(data, wavelet='haar'):
    """ Perform wavelet decomposition """
    coeffs = pywt.wavedec(data, wavelet, level=1)
    return coeffs[0]  # Approximation coefficients (you can use other levels or coefficients)

def wavelet_reconstruction(coeffs, wavelet='haar'):
    """ Perform wavelet reconstruction """
    return pywt.waverec([coeffs, None], wavelet)

def wave_cnn_lstm_forecasting(data, seq_length=24, n_steps=5, test_size=0.3, epochs=100, batch_size=16, output_file="forecast_results.xlsx"):
    # 1. Preprocess data
    df = data.copy()
    df.set_index('temps', inplace=True)
    scaler = MinMaxScaler()
    df_scaled = scaler.fit_transform(df)

    # 2. Convert to supervised learning problem
    def create_dataset(data, time_steps=1):
        X, y = [], []
        for i in range(len(data) - time_steps):
            X.append(data[i:i + time_steps])
            y.append(data[i + time_steps])
        return np.array(X), np.array(y)

    X, y = create_dataset(df_scaled, seq_length)

    # Apply wavelet decomposition to the input data outside the Keras model
    X_wavelet = np.array([wavelet_decomposition(seq) for seq in X])

    # Reshape for CNN-LSTM input (samples, time steps, features)
    X_wavelet = X_wavelet.reshape((X_wavelet.shape[0], X_wavelet.shape[1], 1))

    # 3. Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X_wavelet, y, test_size=test_size, shuffle=False)

    # 4. Build CNN-LSTM model
    model = Sequential()
    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))
    model.add(MaxPooling1D(pool_size=2))
    model.add(LSTM(32, activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')

    # 5. Fit model
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)

    # 6. Multi-step forecasting function
    def multi_step_forecast(model, X_input, n_steps):
        predictions = []
        input_seq = X_input.copy()

        for step in range(n_steps):
            pred = model.predict(input_seq.reshape(1, seq_length, 1))[0]
            predictions.append(pred)
            input_seq = np.append(input_seq[1:], pred)  # Shift the window forward

        return np.array(predictions)

    # 7. Generate 1 to 6 step ahead forecasts and save in DataFrame
    forecast_results = pd.DataFrame()
    y_real = scaler.inverse_transform(X_test[:, -1].reshape(-1, 1)).flatten()
    forecast_results['y_real'] = y_real  # Add the true values as 'y_real'

    for i in range(1, n_steps + 1):
        y_pred = []
        for j in range(len(X_test)):
            input_seq = X_test[j]
            forecast = multi_step_forecast(model, input_seq, i)
            y_pred.append(forecast[-1])  # Take the ith step prediction
        forecast_results[f'{i}_step'] = scaler.inverse_transform(np.array(y_pred).reshape(-1, 1)).flatten()

    # 8. Save forecast results to Excel
    forecast_results.to_excel(output_file, index=False)

    # 9. Plot all columns of forecast_df
    plt.figure(figsize=(12, 8))
    for column in forecast_results.columns:
        plt.plot(forecast_results.index, forecast_results[column], label=column)

    plt.title('Forecasts for Different Steps')
    plt.xlabel('Date')
    plt.ylabel('Forecasted Value')
    plt.legend()
    plt.grid(True)
    plt.show()

    return forecast_results